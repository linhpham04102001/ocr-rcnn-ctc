{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOb4ZiJb60GuB7HN8lE5ku/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["## Import Library and Download Data"],"metadata":{"id":"JHHOwRowHzTA"}},{"cell_type":"code","source":["!pip install -U --no-cache-dir gdown --pre\n","!gdown --id 1j_0RvUWpFchxW4BaZERrJx7oZOz7tFc4"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d6U7xl2LHffY","executionInfo":{"status":"ok","timestamp":1675700642472,"user_tz":-420,"elapsed":22059,"user":{"displayName":"Lĩnh Phạm","userId":"10163718421944748807"}},"outputId":"a71bb649-28a2-4fb6-b079-5bbf0c4473d9"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gdown in /usr/local/lib/python3.8/dist-packages (4.4.0)\n","Collecting gdown\n","  Downloading gdown-4.6.0-py3-none-any.whl (14 kB)\n","Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from gdown) (2.25.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from gdown) (1.15.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from gdown) (4.6.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from gdown) (3.9.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.64.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (2022.12.7)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->gdown) (1.7.1)\n","Installing collected packages: gdown\n","  Attempting uninstall: gdown\n","    Found existing installation: gdown 4.4.0\n","    Uninstalling gdown-4.4.0:\n","      Successfully uninstalled gdown-4.4.0\n","Successfully installed gdown-4.6.0\n","/usr/local/lib/python3.8/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n","  warnings.warn(\n","Downloading...\n","From: https://drive.google.com/uc?id=1j_0RvUWpFchxW4BaZERrJx7oZOz7tFc4\n","To: /content/data_ocr.zip\n","100% 370M/370M [00:09<00:00, 39.9MB/s]\n"]}]},{"cell_type":"code","source":["!unzip data_ocr.zip"],"metadata":{"id":"FYbIDGzqHfiW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!rm -rf data_ocr.zip"],"metadata":{"id":"V9OTRE3iHfnb","executionInfo":{"status":"ok","timestamp":1675700657816,"user_tz":-420,"elapsed":529,"user":{"displayName":"Lĩnh Phạm","userId":"10163718421944748807"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import json\n","import cv2\n","import os, random\n","import numpy as np\n","import itertools\n","import editdistance\n","import json\n","\n","\n","import tensorflow as tf \n","import keras\n","\n","from keras.preprocessing import image\n","from tensorflow.keras.utils import load_img, img_to_array \n","from keras import applications\n","from keras.applications.vgg16 import preprocess_input\n","from sklearn.model_selection import KFold\n","\n","from keras.layers import Input, Dense, Activation, Bidirectional, Dropout\n","from keras.layers import Reshape, Lambda, BatchNormalization\n","from keras.layers import LSTM\n","from keras.layers import add, concatenate\n","\n","from keras.models import Model\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, ModelCheckpoint"],"metadata":{"id":"AOp3hk8xHfqV","executionInfo":{"status":"ok","timestamp":1675700665226,"user_tz":-420,"elapsed":2995,"user":{"displayName":"Lĩnh Phạm","userId":"10163718421944748807"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Processing data"],"metadata":{"id":"Gis-DuAaE5qd"}},{"cell_type":"code","source":["letters = \" #'()+,-./:0123456789ABCDEFGHIJKLMNOPQRSTUVWXYabcdeghiklmnopqrstuvxyzÂÊÔàáâãèéêìíòóôõùúýăĐđĩũƠơưạảấầẩậắằẵặẻẽếềểễệỉịọỏốồổỗộớờởỡợụủỨứừửữựỳỵỷỹ\"\n","MAX_LEN = 70\n","SIZE = 2560, 160\n","CHAR_DICT = len(letters) + 1\n","\n","def text_to_labels(text):\n","    return list(map(lambda x: letters.index(x), text))\n","\n","def labels_to_text(labels):\n","    return ''.join(list(map(lambda x: letters[x] if x < len(letters) else \"\", labels)))\n","\n","def ctc_lambda_func(args):\n","    y_pred, labels, input_length, label_length = args\n","    y_pred = y_pred[:, 2:, :]\n","    return keras.backend.ctc_batch_cost(labels, y_pred, input_length, label_length)\n","\n","def decode_batch(out):\n","    ret = []\n","    for j in range(out.shape[0]):\n","        out_best = list(np.argmax(out[j, 2:], 1))\n","        out_best = [k for k, g in itertools.groupby(out_best)]\n","        outstr = labels_to_text(out_best)\n","        ret.append(outstr)\n","    return ret\n","\n","class TextImageGenerator:\n","    def __init__(self, img_dirpath, labels_path, img_w, img_h,\n","                 batch_size, downsample_factor, idxs, training=True, max_text_len=9, n_eraser=5):\n","        self.img_h = img_h\n","        self.img_w = img_w\n","        self.batch_size = batch_size\n","        self.max_text_len = max_text_len\n","        self.idxs = idxs\n","        self.downsample_factor = downsample_factor\n","        self.img_dirpath = img_dirpath                  \n","        self.labels= json.load(open(labels_path)) if labels_path != None else None\n","        self.img_dir = os.listdir(self.img_dirpath)   \n","        if self.idxs is not None:\n","            self.img_dir = [self.img_dir[idx] for idx in self.idxs]\n","\n","        self.n = len(self.img_dir) # có một file labels.json                      \n","        if \"labels.json\" in self.img_dir:\n","          self.n -= 1\n","        self.indexes = list(range(self.n))\n","        self.cur_index = 0\n","        self.imgs = np.zeros((self.n, self.img_h, self.img_w, 3), dtype=np.float16)\n","        self.training = training\n","        self.texts = []\n","\n","    def build_data(self):\n","        print(self.n, \" Image Loading start... \", self.img_dirpath)\n","        count = 0\n","        for i, img_file in enumerate(self.img_dir):\n","            prefit = img_file.split(\".\")[-1]\n","            if prefit == \"json\":\n","              # print(prefit)\n","              continue\n","              \n","            img = load_img(self.img_dirpath + img_file, target_size=SIZE[::-1])\n","            img = img_to_array(img)\n","            img = preprocess_input(img).astype(np.float16)\n","            self.imgs[count] = img\n","            count+=1\n","            if self.labels != None: \n","                self.texts.append(self.labels[img_file])\n","            else:\n","                #valid mode\n","                self.texts.append('')\n","        print(\"Image Loading finish...\")\n","\n","    def next_sample(self):\n","        self.cur_index += 1\n","        if self.cur_index >= self.n:\n","            self.cur_index = 0\n","            random.shuffle(self.indexes)\n","        return self.imgs[self.indexes[self.cur_index]].astype(np.float32), self.texts[self.indexes[self.cur_index]]\n","\n","    def next_batch(self):\n","        while True:\n","            X_data = np.zeros([self.batch_size, self.img_w, self.img_h, 3], dtype=np.float32)     \n","            Y_data = np.zeros([self.batch_size, self.max_text_len], dtype=np.float32)             \n","            input_length = np.ones((self.batch_size, 1), dtype=np.float32) * (self.img_w // self.downsample_factor - 2)  \n","            label_length = np.zeros((self.batch_size, 1), dtype=np.float32)          \n","\n","            for i in range(self.batch_size):\n","                img, text = self.next_sample()\n","                img = img.transpose((1, 0, 2))\n","                \n","                X_data[i] = img\n","                Y_data[i,:len(text)] = text_to_labels(text)\n","                label_length[i] = len(text)\n","\n","            inputs = {\n","                'the_inputs': X_data,  \n","                'the_labels': Y_data,  \n","                'input_length': input_length,  \n","                'label_length': label_length  \n","            }\n","            outputs = {'ctc': np.zeros([self.batch_size])}  \n","            yield (inputs, outputs)"],"metadata":{"id":"tsTmvNEGDGfR","executionInfo":{"status":"ok","timestamp":1675700673734,"user_tz":-420,"elapsed":3,"user":{"displayName":"Lĩnh Phạm","userId":"10163718421944748807"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Building model"],"metadata":{"id":"fYFfBPvYEiJ1"}},{"cell_type":"code","source":["# Backbone CNN \n","\n","def get_model(input_shape, training):\n","    inputs = Input(name='the_inputs', shape=input_shape, dtype='float32')\n","    base_model = applications.VGG16(weights='imagenet', include_top=False)\n","    \n","    inner = base_model(inputs)\n","    inner = Reshape(target_shape=(int(inner.shape[1]), -1), name='reshape')(inner)\n","    inner = Dense(512, activation='relu', kernel_initializer='he_normal', name='dense1')(inner) \n","\n","    lstm = LSTM(512, return_sequences=True, kernel_initializer='he_normal', name='lstm1', dropout=0.25, recurrent_dropout=0.25)(inner) \n","\n","    y_pred = Dense(CHAR_DICT, activation='softmax', kernel_initializer='he_normal',name='dense2')(lstm)\n","    \n","    labels = Input(name='the_labels', shape=[MAX_LEN], dtype='float32')\n","    input_length = Input(name='input_length', shape=[1], dtype='int64')\n","    label_length = Input(name='label_length', shape=[1], dtype='int64')\n","\n","    loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\n","    \n","    if training:\n","        return Model(inputs=[inputs, labels, input_length, label_length], outputs=loss_out) \n","    else:\n","        return Model(inputs=[inputs], outputs=y_pred)"],"metadata":{"id":"ZXLPj8d2DGtx","executionInfo":{"status":"ok","timestamp":1675700678416,"user_tz":-420,"elapsed":1,"user":{"displayName":"Lĩnh Phạm","userId":"10163718421944748807"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["# Training Model"],"metadata":{"id":"EqyIOM3-Ez-I"}},{"cell_type":"code","source":["def train_kfold(idx, kfold, datapath, labelpath,  epochs, batch_size, lr):\n","\n","    model = get_model((*SIZE, 3), training=True)\n","    opt = Adam(lr=lr)\n","    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=opt)\n","\n","    ## load data\n","    train_idx, valid_idx = kfold[idx]\n","    train_generator = TextImageGenerator(datapath, labelpath, *SIZE, batch_size, 32, train_idx, True, MAX_LEN)\n","    train_generator.build_data()\n","    valid_generator  = TextImageGenerator(datapath, labelpath, *SIZE, batch_size, 32, valid_idx, False, MAX_LEN)\n","    valid_generator.build_data()\n","\n","    ## callbacks\n","\n","    weight_path = 'best_%d.h5' % idx\n","    early_stop = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10, mode='min', verbose=1)\n","    ckp = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True)\n","\n","    #if finetune:\n","       #print('load pretrain model')\n","       #model.load_weights(weight_path)\n","\n","    model.fit_generator(generator=train_generator.next_batch(),\n","                    steps_per_epoch=int(len(train_idx) / batch_size),\n","                    epochs=epochs,\n","                    callbacks=[ckp, early_stop],\n","                    validation_data=valid_generator.next_batch(),\n","                    validation_steps=int(len(valid_idx) / batch_size))\n","    \n","def train(datapath, labelpath, epochs, batch_size, lr):\n","    nsplits = 5\n","\n","    nfiles = np.arange(len(os.listdir(datapath)))\n","\n","    kfold = list(KFold(nsplits, random_state=2018, shuffle=True).split(nfiles))\n","    for idx in range(nsplits):\n","        train_kfold(idx, kfold, datapath, labelpath, epochs, batch_size, lr)"],"metadata":{"id":"zbboXt8sDGv3","executionInfo":{"status":"ok","timestamp":1675700921461,"user_tz":-420,"elapsed":373,"user":{"displayName":"Lĩnh Phạm","userId":"10163718421944748807"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["train_dir = \"data_ocr/\"\n","label_path = \"data_ocr/labels.json\"\n","epochs = 3\n","batch_size = 4 \n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=str(0)\n","finetune = 0\n","lr = 0.001 \n","\n","train(train_dir, label_path, epochs, batch_size, lr)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NjK7kMq7Ew4H","outputId":"da0c5855-ff2a-4d1c-8df2-8be6023f52e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 2s 0us/step\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["1458  Image Loading start...  data_ocr/\n","Image Loading finish...\n","365  Image Loading start...  data_ocr/\n","Image Loading finish...\n","Epoch 1/3\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-9-7f4eabf96b37>:24: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(generator=train_generator.next_batch(),\n"]},{"output_type":"stream","name":"stdout","text":["364/364 [==============================] - ETA: 0s - loss: 206.6029\n","Epoch 1: val_loss improved from inf to 211.17636, saving model to best_0.h5\n","364/364 [==============================] - 362s 944ms/step - loss: 206.6029 - val_loss: 211.1764\n","Epoch 2/3\n","364/364 [==============================] - ETA: 0s - loss: 202.2280\n","Epoch 2: val_loss improved from 211.17636 to 210.69873, saving model to best_0.h5\n","364/364 [==============================] - 349s 959ms/step - loss: 202.2280 - val_loss: 210.6987\n","Epoch 3/3\n","364/364 [==============================] - ETA: 0s - loss: 203.5869\n","Epoch 3: val_loss did not improve from 210.69873\n","364/364 [==============================] - 347s 955ms/step - loss: 203.5869 - val_loss: 213.0997\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["1458  Image Loading start...  data_ocr/\n","Image Loading finish...\n","365  Image Loading start...  data_ocr/\n","Image Loading finish...\n","Epoch 1/3\n","364/364 [==============================] - ETA: 0s - loss: 206.4976\n","Epoch 1: val_loss improved from inf to 210.62976, saving model to best_1.h5\n","364/364 [==============================] - 347s 944ms/step - loss: 206.4976 - val_loss: 210.6298\n","Epoch 2/3\n","364/364 [==============================] - ETA: 0s - loss: 203.5633\n","Epoch 2: val_loss did not improve from 210.62976\n","364/364 [==============================] - 344s 946ms/step - loss: 203.5633 - val_loss: 214.8906\n","Epoch 3/3\n","364/364 [==============================] - ETA: 0s - loss: 201.9864\n","Epoch 3: val_loss did not improve from 210.62976\n","364/364 [==============================] - 346s 950ms/step - loss: 201.9864 - val_loss: 226.0658\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"G4BADPyQEw7F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"th_iSVc3Ew9_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uaF8xqVzExCj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"X2IcPF-HExFG"},"execution_count":null,"outputs":[]}]}